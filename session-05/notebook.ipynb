{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 5: Text Playground\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/level-2-course-material/blob/main/session-05/notebook.ipynb)\n",
    "\n",
    "Same model, same prompt — different output. Control the chaos with sliders."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup — run this cell first!\n",
    "!pip install -q transformers torch\n",
    "\n",
    "from transformers import pipeline\n",
    "print(\"Loading distilgpt2...\")\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "print(\"Model loaded!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Built Tonight\n",
    "\n",
    "We built a **Text Playground** — a Space with sliders that control how the AI writes.\n",
    "\n",
    "The model (`distilgpt2`) never changes. The sliders change **how** it picks words.\n",
    "\n",
    "Check out the live Space: [Text Playground on Hugging Face](https://huggingface.co/spaces/profplate/text-playground)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate text with specific settings\n",
    "prompt = \"Once upon a time in a school where robots\"\n",
    "\n",
    "result = generator(\n",
    "    prompt,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    max_length=60,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(result[0][\"generated_text\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature: Low vs. High\n",
    "\n",
    "Temperature controls randomness. Low = predictable. High = creative/chaotic."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Same prompt, three different temperatures\n",
    "prompt = \"The secret ingredient in the recipe was\"\n",
    "\n",
    "for temp in [0.1, 0.7, 1.5]:\n",
    "    result = generator(\n",
    "        prompt,\n",
    "        temperature=max(temp, 0.01),\n",
    "        top_p=0.9,\n",
    "        max_length=50,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "    print(f\"Temperature = {temp}:\")\n",
    "    print(result[0][\"generated_text\"])\n",
    "    print(\"---\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-p: Narrow vs. Wide\n",
    "\n",
    "Top-p controls how many words the model considers. Low = only the top picks. High = more variety."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Same prompt, different top-p values (temperature fixed at 0.7)\n",
    "prompt = \"The secret ingredient in the recipe was\"\n",
    "\n",
    "for top_p in [0.1, 0.5, 0.9]:\n",
    "    result = generator(\n",
    "        prompt,\n",
    "        temperature=0.7,\n",
    "        top_p=top_p,\n",
    "        max_length=50,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "    print(f\"Top-p = {top_p}:\")\n",
    "    print(result[0][\"generated_text\"])\n",
    "    print(\"---\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "### Experiment 1: Settings Recipe Cards\n",
    "\n",
    "Find the best settings for each task. Fill in the table below.\n",
    "\n",
    "| Task | Temperature | Top-p | Max Length | Notes |\n",
    "|------|-------------|-------|-----------|-------|\n",
    "| Scary story opening | ? | ? | ? | |\n",
    "| Formal email to a teacher | ? | ? | ? | |\n",
    "| Funny random story | ? | ? | ? | |\n",
    "| News headline continuation | ? | ? | ? | |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Experiment 1: Try different settings for a scary story\n",
    "# Change the temperature, top_p, and max_length to find the best combo\n",
    "\n",
    "prompt = \"The haunted house at the end of the street\"  # Change this prompt for each task\n",
    "\n",
    "result = generator(\n",
    "    prompt,\n",
    "    temperature=0.7,    # Try: 0.1, 0.5, 0.7, 1.0, 1.5\n",
    "    top_p=0.9,          # Try: 0.1, 0.5, 0.9\n",
    "    max_length=80,       # Try: 30, 60, 80, 150\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(result[0][\"generated_text\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Experiment 2: Run the SAME settings on two very different prompts\n",
    "# Do good settings for one task work for another?\n",
    "\n",
    "settings = {\"temperature\": 1.0, \"top_p\": 0.9, \"max_length\": 60}\n",
    "\n",
    "prompts = [\n",
    "    \"Dear Principal, I am writing to request\",\n",
    "    \"Breaking news: scientists discover that cats\",\n",
    "]\n",
    "\n",
    "for p in prompts:\n",
    "    result = generator(p, do_sample=True, num_return_sequences=1, **settings)\n",
    "    print(f\"Prompt: {p}\")\n",
    "    print(result[0][\"generated_text\"])\n",
    "    print(\"---\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Experiment 3: Extreme settings — what happens at the edges?\n",
    "# Try temperature = 2.0 and see what happens\n",
    "\n",
    "prompt = \"In the year 2050, schools will\"\n",
    "\n",
    "result = generator(\n",
    "    prompt,\n",
    "    temperature=2.0,\n",
    "    top_p=1.0,\n",
    "    max_length=80,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(\"Temperature = 2.0, Top-p = 1.0:\")\n",
    "print(result[0][\"generated_text\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Create **3 settings recipe cards** for 3 different writing tasks. For each one, write:\n",
    "- The task name\n",
    "- The prompt you used\n",
    "- The best temperature, top-p, and max length\n",
    "- Your favorite output\n",
    "\n",
    "**GitHub:** If you haven't uploaded a notebook to your `my-ai-portfolio` repo yet, try it this week!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "| Term | Meaning |\n",
    "|------|---------|\n",
    "| **Hyperparameter** | A setting we control at runtime (not learned during training) |\n",
    "| **Temperature** | Controls randomness — low = predictable, high = creative/chaotic |\n",
    "| **Top-p** | Limits which words the model considers — low = only top picks |\n",
    "| **Token** | A piece of text (roughly a word, but not exactly) |\n",
    "| **Text generation** | A model that predicts and writes the next words given a prompt |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}