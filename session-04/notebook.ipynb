{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4: Sentiment Showdown\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/level-2-course-material/blob/main/session-04/notebook.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -q transformers torch\n",
    "from transformers import pipeline\n",
    "print(\"Setup complete!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Built Tonight\n",
    "\n",
    "We put three sentiment models head-to-head on the same text and asked: which one is \"right\"?\n",
    "\n",
    "The answer: it depends on **what you're using it for**. That's model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Three Sentiment Models\n",
    "\n",
    "This takes a minute -- you're downloading three models. Run each cell and wait for the checkmark."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model 1: Trained on movie reviews (POSITIVE / NEGATIVE only)\n",
    "model_movie = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "print(\"Movie review model loaded!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model 2: Trained on 124 million tweets (positive / neutral / negative)\n",
    "model_twitter = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "print(\"Twitter model loaded!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model 3: Trained on product reviews (1 star to 5 stars)\n",
    "model_product = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "print(\"Product review model loaded!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Showdown\n",
    "\n",
    "All three models read the same text. Do they agree?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "text = \"The service was slow but the food was amazing.\"\n",
    "\n",
    "r1 = model_movie(text)[0]\n",
    "r2 = model_twitter(text)[0]\n",
    "r3 = model_product(text)[0]\n",
    "\n",
    "print(f\"Movie Review Model:   {r1['label']} ({r1['score']:.0%})\")\n",
    "print(f\"Twitter Model:        {r2['label']} ({r2['score']:.0%})\")\n",
    "print(f\"Product Review Model: {r3['label']} ({r3['score']:.0%})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "### Experiment 1: Try 5 inputs and keep score\n",
    "\n",
    "**Try this:** Run each input and fill in the table below.\n",
    "\n",
    "| Input | Movie Model | Twitter Model | Product Model | Do they agree? |\n",
    "|-------|------------|---------------|---------------|----------------|\n",
    "| (your text) | | | | |\n",
    "| (your text) | | | | |\n",
    "| (your text) | | | | |\n",
    "| (your text) | | | | |\n",
    "| (your text) | | | | |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Try this: change the text and run again\n",
    "text = \"lol this is SO bad it's actually good\"\n",
    "\n",
    "r1 = model_movie(text)[0]\n",
    "r2 = model_twitter(text)[0]\n",
    "r3 = model_product(text)[0]\n",
    "\n",
    "print(f\"Movie Review Model:   {r1['label']} ({r1['score']:.0%})\")\n",
    "print(f\"Twitter Model:        {r2['label']} ({r2['score']:.0%})\")\n",
    "print(f\"Product Review Model: {r3['label']} ({r3['score']:.0%})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Find maximum disagreement\n",
    "\n",
    "**Try this:** Can you find a sentence where all three models give completely different answers?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Try this: find the most disagreement you can\n",
    "text = \"I can't believe how terrible this is. Just kidding, it's great!\"\n",
    "\n",
    "r1 = model_movie(text)[0]\n",
    "r2 = model_twitter(text)[0]\n",
    "r3 = model_product(text)[0]\n",
    "\n",
    "print(f\"Movie Review Model:   {r1['label']} ({r1['score']:.0%})\")\n",
    "print(f\"Twitter Model:        {r2['label']} ({r2['score']:.0%})\")\n",
    "print(f\"Product Review Model: {r3['label']} ({r3['score']:.0%})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Try sarcasm\n",
    "\n",
    "**Try this:** Sarcasm is hard for AI. Which model handles it best?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Try this: does any model \"get\" sarcasm?\n",
    "text = \"10/10 would not recommend\"\n",
    "\n",
    "r1 = model_movie(text)[0]\n",
    "r2 = model_twitter(text)[0]\n",
    "r3 = model_product(text)[0]\n",
    "\n",
    "print(f\"Movie Review Model:   {r1['label']} ({r1['score']:.0%})\")\n",
    "print(f\"Twitter Model:        {r2['label']} ({r2['score']:.0%})\")\n",
    "print(f\"Product Review Model: {r3['label']} ({r3['score']:.0%})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Neutral text\n",
    "\n",
    "**Try this:** The movie review model has no \"neutral\" label. What does it do with neutral text?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Try this: what happens with genuinely neutral text?\n",
    "text = \"The movie was fine. Nothing special but not bad either.\"\n",
    "\n",
    "r1 = model_movie(text)[0]\n",
    "r2 = model_twitter(text)[0]\n",
    "r3 = model_product(text)[0]\n",
    "\n",
    "print(f\"Movie Review Model:   {r1['label']} ({r1['score']:.0%})\")\n",
    "print(f\"Twitter Model:        {r2['label']} ({r2['score']:.0%})\")\n",
    "print(f\"Product Review Model: {r3['label']} ({r3['score']:.0%})\")\n",
    "print()\n",
    "print(\"Notice: the movie model HAS to pick POSITIVE or NEGATIVE -- it has no neutral!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "If you had to pick **one** of these three models for a real project, which would you pick and why? It depends on what kind of text your users would input.\n",
    "\n",
    "---\n",
    "\n",
    "**GitHub skill:** Upload this notebook to your `my-ai-portfolio` repo (same as last time -- reinforce the habit!):\n",
    "1. Go to your repo on github.com\n",
    "2. Click **Add file** -> **Upload files**\n",
    "3. Drag your `.ipynb` file and click **Commit changes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "| Term | Meaning |\n",
    "|------|--------|\n",
    "| **Model evaluation** | The process of measuring how well a model performs on a specific task |\n",
    "| **Sentiment analysis** | Detecting positive, negative, or neutral feeling in text |\n",
    "| **Confidence score** | How sure the model is about its answer (shown as a percentage) |\n",
    "| **Domain** | The type of text a model was trained on (tweets, reviews, news, etc.) |\n",
    "| **False positive** | Model says YES when the answer is actually NO |\n",
    "| **False negative** | Model says NO when the answer is actually YES |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}